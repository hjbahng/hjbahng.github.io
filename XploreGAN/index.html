<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <title>Exploring Unlabeled Faces for Novel Attribute Discovery</title>
    <style type="text/css">
    .center {
        text-align: center;
    }

    .lead {
        font-size: 1.0rem;
        font-family: Georgia, "Times New Roman", Times, serif;
    }
    
    .subtitle {
        font-size: 1.6rem;
        font-family: Georgia, "Times New Roman", Times, serif;
    }

    .author {
        font-size: 1.1rem;
        font-family: Georgia, "Times New Roman", Times, serif;
    }
    
    .title {
        font-size: 2.0rem;
        font-family: Georgia, "Times New Roman", Times, serif;
    }
	   
    img.resize {
    max-width:70%;
    max-height:70%;
    }

    .figure-caption {
        color: #6c757d;
	font-family: Georgia, "Times New Roman", Times, serif;
    }
    </style>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-141263633-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-141263633-1');
    </script>
</head>

<body>
    <div class="container" style="margin-top:20px;">
        <div class="row">
            <div class="col-md-2"></div>
            <div class="col-md-8">
                <center><h1 class="title">Exploring Unlabeled Faces for Novel Attribute Discovery</h1></center>
                <!-- author -->
                <center><h2 class="author">
                    <a href="https://hjbahng.github.io">Hyojin Bahng</a>&nbsp;&nbsp;&nbsp;
                    <a href="">Sunghyo Chung</a>&nbsp;&nbsp;&nbsp;
                    <a href="https://sjooyoo.github.io">Seungjoo Yoo</a>&nbsp;&nbsp;&nbsp;
                    <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>&nbsp;&nbsp;&nbsp;
                </h2></center>
                <center><h2 class="author">
		    Korea University
	        </h2></center>
                <!-- Teaser -->
                <center>
                    <figure class="figure">
                        <img src="./figs/teaser_image_v5.jpg" class="figure-img img-fluid" alt="Responsive image" style="margin:20px 0px;">
                        <figcaption class="figure-caption text-justify">
                            Given raw, unlabeled data, our algorithm discovers novel facial attributes and performs high-quality multi-domain
				image translation. All results are based on newly-found attributes from our algorithm (e.g., a wide rage of ethnicity, skin and
				hair color, age, facial hair, accessories, makeup). We did not use any pre-defined attribute labels to generate the results.
			</figcaption>
                    </figure>
                </center>
                <!-- Abstract -->
                <hr>
                <div>
                    <h2 class="subtitle">Abstract</h2>
                    <p class="lead text-justify">
                        Despite remarkable success in unpaired image-to-image translation, existing systems still require a large amount of
			labeled images. This is a bottleneck for their real-world applications; in practice, a model trained on labeled CelebA
			dataset does not work well for test images from a different distribution â€“ greatly limiting their application to unlabeled images of a much larger quantity. In this paper, we
			attempt to alleviate this necessity for labeled data in the facial image translation domain. We aim to explore the degree 
			    to which you can discover novel attributes from unlabeled faces and perform high-quality translation. To this end, we
				use prior knowledge about the visual world as guidance to discover novel attributes and transfer them via a novel
				normalization method. Experiments show that our method trained on unlabeled data produces high-quality translations, 
			    preserves identity, and be perceptually realistic as good as, or better than, state-of-the-art methods trained on labeled data.
			</p>
                </div>
                <hr>
                <div>
                    <h2 class="subtitle">Paper</h2>
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./figs/paper.png" class="img-fluid border" alt="" style="margin:20px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <div class="align-middle">
                                <a href="">[Paper]</a>
                                <a href="">[Bibtex]</a>
                                <p class="lead">
                                    ArXiv, 2019.
                                    <br>
                                    Hyojin Bahng, Sunghyo Chung, Seungjoo Yoo, and Jaegul Choo. "Exploring Unlabeled Faces for Novel Attribute Discovery".
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
<!--                 <hr>
                <div> -->
                    <!-- video -->
<!--                     <h2 class="subtitle">Video</h2>
                    <div class="embed-responsive embed-responsive-16by9">
                        <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/m8_kCEbfwaE" allowfullscreen></iframe> 
                    </div>
		    </div> -->
                <hr>
                <div>
                    <h2 class="subtitle">Additional Results</h2>
                    <center>
                        <figure class="figure">
                            <img src="./figs/supp_ffhq.png" class="figure-img img-fluid" alt="Responsive image">
                        </figure>
                    </center>
                    <center>
                        <figure class="figure">
                            <img src="./figs/supp_ffhq2.png" class="figure-img img-fluid" alt="Responsive image">
                        </figure>
                    </center>
                    <center>
                        <figure class="figure">
                            <img src="./figs/supp_fig4.jpg" class="figure-img img-fluid" alt="Responsive image">
                        </figure>
                    </center>
                    <center>
                        <figure class="figure">
                            <img src="./figs/supp_fig6.jpg" class="figure-img img-fluid" alt="Responsive image">
                            <!-- <figcaption class="figure-caption text-justify">
                                <center>
                                    Figure 4. Additional qualitative samples of CelebA dataset.
                                </center>
                            </figcaption> -->
                        </figure>
                    </center>
                    <center>
                        <figure class="figure">
                            <img src="./figs/supp_fig7.jpg" class="figure-img img-fluid" alt="Responsive image">
                            <!-- <figcaption class="figure-caption text-justify">
                                <center>
                                    Figure 5. Additional qualitative samples of CelebA dataset.
                                </center>
                            </figcaption>
 -->
                        </figure>
                    </center>
                </div>
            </div>
        </div>
    </div>
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
</body>

</html>
