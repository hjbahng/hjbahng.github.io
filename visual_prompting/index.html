<!DOCTYPE html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1000px;
	}

	h1 {
		font-weight:300;
		font-size:24px;
	}

	code {
    font-size: 0.8rem;
    margin: 0 0.1rem;
    padding: 0.1rem 0.1rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
}

pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
    text-align: left;
}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1.5px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}

	p.small {
		font-size: 12px
	}
</style>

<html>
  <head>
		<title>Learning to generate line drawings that convey geometry and semantics</title>
<!-- 		<meta property="og:image" content="http://people.eecs.berkeley.edu/~tinghuiz/projects/mpi/images/teaser.png"/>
		<meta property="og:title" content="Stereo Magnification: Learning View Synthesis using Multiplane Images" /> -->
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:36px">Visual Prompting: Modifying Pixel Space to Adapt Pre-trained Models</span>
	</center>
 
	<br>
  	<table align=center width=700px>
  	 <tr>
		<td align=center width=100px>
		<center>
		<span style="font-size:20px"><a href='https://hjbahng.github.io/'>Hyojin Bahng</a></span>
		</center>
		</td>

		<td align=center width=100px>
		<center>
		<span style="font-size:20px"><a href="http://people.csail.mit.edu/jahanian/">Ali Jahanian*</a></span>
		</center>
		</td>
		 
		<td align=center width=100px>
		<center>
		<span style="font-size:20px"><a href="https://swamiviv.github.io/">Swami Sankaranarayanan*</a></span>
		</center>
		</td>

		<td align=center width=100px>
		<center>
		<span style="font-size:20px"><a href="http://web.mit.edu/phillipi/">Phillip Isola</a></span>
		</center>
		</td>

	 </tr>
	</table>

	<table align=center width=700px>
  	 <tr>
		<td align=center width=100px>
		<center>
		<span style="font-size:20px">MIT CSAIL</span></center>
		</center>
		</td>
	 </tr>
	</table>

		<br>
<!-- 	<table align=center width=700px>
  	 <tr>
		<td align=center width=100px>
		<center>
		<span style="font-size:18px">To appear in CVPR 2022</span></center>
		</center>
		</td>
	 </tr>
	</table> -->

	<table align=center width=500px style="margin-top:30px">
  	 <tr>
		<td align=center width=50px>
		<center>
		<span style="font-size:24px"><a href="">[Paper]</a></span>
		</center>
		</td>

		<td align=center width=50px>
		<center>
		<span style="font-size:24px"><a href="">[Code]</a></span>
		</center>
		</td>

	 </tr>
	</table>
 
  		  <br>
  		  <table align=center width=900px>
  			  <tr>
  	              <td width=600px>
  					<center>
  	                	<a href="./images/teaser.png"><img src = "./images/teaser.png" width="1000px"></img></href></a><br>
					</center>
  	              </td>
  	          </tr>
  		  </table>

  		  <table align=center width=1000>
	 		<center><h1 style="margin-top:35px">Abstract</h1></center>
  			  <tr>
				  <td>
				  	<br>
			      	  <p style="text-align:justify;margin-top:-30px">
					  Recently, in NLP, prompting has become a new paradigm for lightweight adaptation to down-
stream tasks. Rather than learning task-specific heads, it steers language models to perform a
new task by only reformulating the dataset. In vision, linear probing is the standard approach for
lightweight adaptation while CLIP first introduced textual prompts to enable zero-shot transfer.
In this paper, we explore the question: can we create prompts with pixels? In other words, can
pre-trained models adapt to a new task solely by modifying the pixel space? We introduce visual
prompting which learns a task-specific image perturbation, such that a frozen pre-trained model
prompted with this perturbation performs a new task. We discover that changing only a few pixels
is enough to steer models to adapt to new tasks and domains. We show that our method is applicable
to various vision and vision-language models. The surprising effectiveness of visual prompting
provides a new perspective on how to adapt and utilize pre-trained models in vision. Code is available
at https://github.com/hjbahng/visual_prompting/.
			          	</p>
  	              </td>
              </tr>
  		  </table>



		  <hr>
		 <!-- <table align=center width=550px> -->
  		  <table align=center width=1000 style="text-align: justify;">
	 		<center><h1>Method</h1></center>
  			  <tr>
  			  	<td>
  			  		<img style="height:300px; margin-right: 20px;" src="images/method.png"/>
  			  	<td>
  	              Our method approaches line drawing generation as an unsupervised image translation problem which uses various losses to assess the information communicated in a line drawing. Our key idea is to view the problem as an encoding through a line drawing and to maximize the quality of this encoding through explicit geometry, semantic, and appearance decoding objectives. This evaluation is performed by deep learning methods which decode depth, semantics, and appearance from line drawings. The aim is for the extracted depth and semantic information to match the scene geometry and semantics of the input photographs.
  	          </td>
              </tr>
  		  </table>
<!-- 		  <br>

  		  	<hr>
  		  	<div id='video'>
			<center><h1>Video</h1>

			<table align=center width=800px>
				<tr>
				<td>
					<video width="800px" controls>
					  <source src="images/projectvideo2.mp4" type="video/mp4">
					Your browser does not support the video tag.
					</video>
				</td>

				</tr>
			</table>
			</center>
			</div> -->
		<br>
	  
	  	<hr>

	  	<center><h1>Bibtex</h1>

			<table align=center width=800px>
				<tr>
				<td>
		      <pre><code>
	      @inproceedings{chan2022drawings,
	      title={Learning to generate line drawings that convey geometry and semantics},
	      author={Chan, Caroline and Durand, Fr&eacute;do and Isola, Phillip},
	      booktitle={CVPR},
	      year={2022}
	      }
      </code></pre>
					</td>

				</tr>
			</table>
			</center>
	  	

  		 <br>

  		  <table align=center width=1000px>
  			  <tr>
  	              <td>
  					<left>
	  		  <center><h1>Acknowledgements</h1></center>
<!-- 	  		  This webpage template was rented from <a href="">Caroline Chen</a>. -->

			</left>
		</td>
		</tr>
		</table>
		<br><br>


</body>
</html>

